{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "\n",
    "#### Qa Given the following $\\mathbf{x}^{(i)}$'s, construct and print the $\\mathbf X$ matrix in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix X:\n",
      "[[ 1  2  3]\n",
      " [ 4  2  1]\n",
      " [ 3  8  5]\n",
      " [-9 -1  0]]\n",
      "\n",
      "Shape of X: (4, 3)\n",
      "X has 4 samples and 3 features\n"
     ]
    }
   ],
   "source": [
    "# Qa\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_true = np.array([1,2,3,4]) # NOTE:  you'll need this later\n",
    "\n",
    "# Define the feature vectors x^(i)\n",
    "x1 = np.array([1, 2, 3])\n",
    "x2 = np.array([4, 2, 1])\n",
    "x3 = np.array([3, 8, 5])\n",
    "x4 = np.array([-9, -1, 0])\n",
    "\n",
    "# Construct the X matrix where each row is (x^(i))^T\n",
    "X = np.array([x1, x2, x3, x4])\n",
    "\n",
    "print(\"Matrix X:\")\n",
    "print(X)\n",
    "print(f\"\\nShape of X: {X.shape}\")\n",
    "print(f\"X has {X.shape[0]} samples and {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Qb Implement the $\\norm{1}$ and $\\norm{2}$ norms for vectors in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx-ty=[-2  3 -1 -2], d1-expected_d1=0.0, d2-expected_d2=0.0\n",
      "OK(part-1)\n",
      "d2dot-expected_d2= 0.0\n",
      "OK(part-2)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def L1(x):\n",
    "    \"\"\"L1 norm using explicit implementation\"\"\"\n",
    "    result = 0.0\n",
    "    for i in range(len(x)):\n",
    "        if x[i] >= 0:\n",
    "            result = result + x[i]\n",
    "        else:\n",
    "            result = result + (-x[i])\n",
    "    return result\n",
    "\n",
    "def L2(x):\n",
    "    \"\"\"L2 norm using explicit implementation\"\"\"\n",
    "    result = 0.0\n",
    "    for i in range(len(x)):\n",
    "        result = result + x[i] * x[i]\n",
    "    return result ** 0.5\n",
    "\n",
    "def L2Dot(x):\n",
    "    \"\"\"L2 norm using numpy dot product\"\"\"\n",
    "    return (np.dot(x, x)) ** 0.5\n",
    "\n",
    "# TEST vectors: here I test your implementation...calling your L1() and L2() functions\n",
    "tx=np.array([1, 2, 3, -1])\n",
    "ty=np.array([3,-1, 4,  1])\n",
    "\n",
    "expected_d1=8.0\n",
    "expected_d2=4.242640687119285\n",
    "\n",
    "d1=L1(tx-ty)\n",
    "d2=L2(tx-ty)\n",
    "\n",
    "print(f\"tx-ty={tx-ty}, d1-expected_d1={d1-expected_d1}, d2-expected_d2={d2-expected_d2}\")\n",
    "\n",
    "eps=1E-9 \n",
    "# NOTE: remember to import 'math' for fabs for the next two lines..\n",
    "assert math.fabs(d1-expected_d1)<eps, \"L1 dist seems to be wrong\" \n",
    "assert math.fabs(d2-expected_d2)<eps, \"L2 dist seems to be wrong\" \n",
    "\n",
    "print(\"OK(part-1)\")\n",
    "\n",
    "# comment-in once your L2Dot fun is ready...\n",
    "d2dot=L2Dot(tx-ty)\n",
    "print(\"d2dot-expected_d2=\",d2dot-expected_d2)\n",
    "assert math.fabs(d2dot-expected_d2)<eps, \"L2Dot dist seem to be wrong\" \n",
    "print(\"OK(part-2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why defined L1:\n",
    "Explanation: Manual absolute value calculation without using built-in abs(). \n",
    "\n",
    "Why defined L2Dot:\n",
    "Explanation: np.dot(x, x) computes x^T * x which equals sum of squares. Much faster than explicit loops for large arrays - this is vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Construct the Root Mean Square Error (RMSE) function (Equation 2-1 [HOML])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=6.576473218982953, diff=2.6645352591003757e-15\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def RMSE(y_pred, y_true):\n",
    "    \"\"\"Root Mean Square Error using L2 norm\"\"\"\n",
    "    diff = y_pred - y_true\n",
    "    n = len(y_true)\n",
    "    mse = (L2(diff) ** 2) / n\n",
    "    return mse ** 0.5\n",
    "\n",
    "\n",
    "# Dummy h function:\n",
    "def h(X):    \n",
    "    if X.ndim!=2:\n",
    "        raise ValueError(\"excpeted X to be of ndim=2, got ndim=\",X.ndim) \n",
    "    if X.shape[0]==0 or X.shape[1]==0:\n",
    "        raise ValueError(\"X got zero data along the 0/1 axis, cannot continue\")\n",
    "    return X[:,0]\n",
    "\n",
    "# Calls your RMSE() function:\n",
    "r=RMSE(h(X), y_true)\n",
    "\n",
    "# TEST vector:\n",
    "eps=1E-9\n",
    "expected=6.57647321898295\n",
    "print(f\"RMSE={r}, diff={r-expected}\")\n",
    "assert math.fabs(r-expected)<eps, \"your RMSE dist seems to be wrong\" \n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "def RMSE(y_pred, y_true):\n",
    "    \"\"\"Root Mean Square Error using L2 norm\"\"\"\n",
    "    diff = y_pred - y_true\n",
    "    n = len(y_true)\n",
    "    mse = (L2(diff) ** 2) / n\n",
    "    return mse ** 0.5\n",
    "```\n",
    "Explinaiton:\n",
    "L2(diff)**2 gives sum of squared differences. Divide by n for mean, then sqrt for RMSE. This shows the mathematical relationship between L2 norm and MSE.\n",
    "\n",
    "```Python\n",
    "def h(X):\n",
    "    return X[:,0]\n",
    "```\n",
    "Explanation: Takes first column as prediction. This simulates a simple ML model that uses only the first feature to predict the target. Used for testing cost functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qd Similar construct the Mean Absolute Error (MAE) function (Equation 2-2 [HOML]) and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE=3.75, diff=0.0\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "def MAE(y_pred, y_true):\n",
    "    \"\"\"Mean Absolute Error using L1 norm\"\"\"\n",
    "    diff = y_pred - y_true\n",
    "    n = len(y_true)\n",
    "    return L1(diff) / n\n",
    "\n",
    "\n",
    "# Calls your MAE function:\n",
    "r=MAE(h(X), y_true)\n",
    "\n",
    "# TEST vector:\n",
    "expected=3.75\n",
    "print(f\"MAE={r}, diff={r-expected}\")\n",
    "assert math.fabs(r-expected)<eps, \"MAE dist seems to be wrong\" \n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qe Robust Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with wrong inputs...\n",
      "L1 failed with 2D array - good\n",
      "RMSE failed with different sizes - good\n",
      "L1 norm of [1,-2,3]: 6.0\n",
      "L2 norm of [1,-2,3]: 3.7416573867739413\n",
      "RMSE: 1.0\n",
      "MAE: 1.0\n",
      "Done testing\n"
     ]
    }
   ],
   "source": [
    "# Testing error handling\n",
    "\n",
    "# Let's check what happens with bad inputs\n",
    "print(\"Testing with wrong inputs...\")\n",
    "\n",
    "try:\n",
    "    L1(np.array([[1,2],[3,4]]))  # 2D instead of 1D\n",
    "except:\n",
    "    print(\"L1 failed with 2D array - good\")\n",
    "\n",
    "try:\n",
    "    L2(np.array([]))  # empty\n",
    "except:\n",
    "    print(\"L2 failed with empty array - good\")\n",
    "    \n",
    "try:\n",
    "    RMSE(np.array([1,2,3]), np.array([1,2]))  # different sizes\n",
    "except:\n",
    "    print(\"RMSE failed with different sizes - good\")\n",
    "\n",
    "# Test normal usage still works\n",
    "x = np.array([1,-2,3])\n",
    "print(f\"L1 norm of [1,-2,3]: {L1(x)}\")\n",
    "print(f\"L2 norm of [1,-2,3]: {L2(x)}\")\n",
    "\n",
    "y_pred = np.array([2,3,4])\n",
    "y_true = np.array([1,2,3]) \n",
    "print(f\"RMSE: {RMSE(y_pred, y_true)}\")\n",
    "print(f\"MAE: {MAE(y_pred, y_true)}\")\n",
    "\n",
    "print(\"Done testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qf Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These exercises covered the mathematical foundation that underlies most machine learning algorithms. We started with basic vector and matrix operations because ML algorithms process data in vectorized form - understanding how to construct data matrices X and target vectors y is essential for any ML work.\n",
    "\n",
    "The norm functions (L1 and L2) are fundamental because they measure distances and similarities between data points. Most ML algorithms need to calculate how \"far apart\" predictions are from actual values, which is exactly what these norms do. L2 norm is especially important as it forms the basis for many optimization algorithms.\n",
    "\n",
    "The cost functions MSE and MAE represent how we measure prediction quality in machine learning. MSE (using L2 norm) is widely used because it heavily penalizes large errors, while MAE (using L1 norm) is more robust to outliers. Understanding these metrics is crucial because the choice of cost function directly influences how an algorithm learns.\n",
    "\n",
    "Building these functions from scratch, rather than using library functions, helped us understand what actually happens \"under the hood\" when we call the libraries. The error handling code is critical not to have in real ML projects where data quality varies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
