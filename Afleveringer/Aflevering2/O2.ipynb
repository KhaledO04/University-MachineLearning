{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18f036d",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "### MAL Group-Nr. 15\n",
    "11-10-2025\n",
    "\n",
    "| Name   | ID        |\n",
    "|--------|-----------|                       \n",
    "| John Nguyen | 202209849 |\n",
    "| Khaled Omar | 202307853 |\n",
    "| Jahye Ali | 202309135 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4901782",
   "metadata": {},
   "source": [
    "## Supergruppe diskussion\n",
    "\n",
    "#### Resume: Look at the Big Picture\n",
    "Et ML-projekt starter ikke i Jupyter, men i virkeligheden. Først skal problemet skæres til: hvad prøver vi at løse, og hvordan ser succes ud for dem, der skal bruge løsningen? Vi afgør, om opgaven er regression, klassifikation eller noget tredje, og vælger metrics, der giver mening for forretningen. Samtidig afklarer vi rammerne: hvilke data findes, hvor rene er de, og er der krav til hastighed, forklarbarhed eller fairness? En simpel baseline fungerer som reality check, så vi kan se, om modellen faktisk slår en tommelfingerregel. Til sidst planlægger vi, hvordan data og feedback løbende kommer tilbage i systemet, så modellen kan blive klogere uden at vi starter forfra hver gang.\n",
    "\n",
    "#### Resume: Get the Data\n",
    "Her handler det om at gøre dataindhentningen kedeligt pålidelig. Man finder kilderne, laver et stabilt snapshot og tænker over privatliv og lækager, inden man bliver for kreativ. Splittet i træning/validering/test bør ligge tidligt, helst på en måde der minder om drift (fx tidsbaseret, hvis problemet er tidsfølsomt). Pointen er, at både du og en anden i gruppen kan genskabe præcis samme datasæt i morgen, uden overraskelser.\n",
    "\n",
    "#### Resume: Explore and Visualize the Data to Gain Insights,\n",
    "EDA er der, hvor man får fornemmelsen for materialet. Man kigger på fordelinger, outliers og relationer for at se, om der er noget, der stikker ud, eller om visse features faktisk hænger sammen med målet. Visualiseringer er mest et værktøj til at stille bedre spørgsmål: ligner træningsdata de cases, vi forventer i produktion, og ændrer tingene sig over tid eller mellem segmenter? Hypoteserne fra EDA’en er retningsgivende for, hvad vi vil prøve senere, men de skal altid bekræftes ordentligt.\n",
    "\n",
    "#### Resume: Prepare the Data for Machine Learning Algorithms\n",
    "Forbehandling er den praktiske del, der gør datasættet brugbart og reproducerbart. Manglende værdier håndteres fornuftigt, numeriske features skaleres, og kategoriske kodning vælges, så det matcher både model og drift. Ofte opstår de bedste forbedringer gennem simpel feature engineering: rigtige transformationer, aggregeringer eller tidsvinduer. Alt pakkes i en pipeline, så det samme sker på præcis samme måde i træning, validering, test—og senere i produktion. Gem state (scalers, encodere), så inferens ikke “glemmer” forbehandlingen.\n",
    "\n",
    "#### Resume: Select and Train a Model\n",
    "Man starter hellere simpelt end ambitiøst, fordi det giver hurtig feedback og et klart sammenligningsgrundlag. Tabsfunktion og evalueringsmål skal passe til problemet, ellers jagter man tal, der ikke betyder noget. Krydsvalidering giver mere stabile estimater, og undervejs holder man øje med under-/overfitting og justerer kompleksitet og regulering. Alle eksperimenter logges (hyperparametre, seed, versioner), så man kan forklare, hvorfor model A slog model B—eller hvorfor den ikke gjorde.\n",
    "\n",
    "#### Resume: Fine-Tune Your Model\n",
    "Tuning handler om at forbedre generalisering uden at snyde. Man søger hyperparametre systematisk, læser læringskurver for at se, om problemet er “for lidt data” eller “for kompleks model”, og overvejer ensembling, hvis det giver stabil gevinst. Det hele balanceres mod praktiske krav: modelstørrelse, latenstid og fortolkbarhed. Den endelige vurdering sker én gang på test-sættet, hvorefter model og pipeline fryses, så man ved, hvad der faktisk blev godkendt.\n",
    "\n",
    "#### Resume: Launch, Monitor, and Maintain Your System\n",
    "I produktion er modellen kun én brik i et system. Man pakker den som service eller batch-job, laver ordentlig versionering og automatiserede tests, og sætter overvågning op på både data og effekt: driftsdrift (data drift), latency, fejl og de KPI’er, der betyder noget for brugerne. Når ting ændrer sig, har man en plan for rollback og kontrollerede udrulninger. Retræning sker efter en tydelig strategi (tid eller triggers), og alt registreres i et model-registry, så man kan audit-spore ændringer. Etik og bias er ikke et engangscheck; det er noget, der genbesøges, når data og brugere udvikler sig.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
