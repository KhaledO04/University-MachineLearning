{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Supergruppe diskussion\n",
    "\n",
    "\n",
    "## § 2 \"End-to-End Machine Learning Project\" [HOML]\n",
    "\n",
    "Genlæs kapitel  § 2 og forbered mundtlig præsentation.\n",
    "\n",
    "## Forberedelse inden lektionen\n",
    "\n",
    "Een eller flere af gruppe medlemmer forbereder et mundtligt resume af § 2:\n",
    "\n",
    "* i skal kunne give et kort mundligt resume af hele § 2 til en anden gruppe (på nær, som nævnt, Create the Workspace og Download the Data),\n",
    "\n",
    "* resume holdes til koncept-plan, dvs. prøv at genfortælle, hvad de overordnede linier er i kapitlerne i [HOML].\n",
    "\n",
    "Lav et kort skriftlig resume af de enkelte underafsnit, ca. 5 til 20 liners tekst, se \"TODO\"-template herunder (MUST, til O2 aflevering).\n",
    "\n",
    "Kapitler (incl. underkapitler):\n",
    "\n",
    "* _Look at the Big Picture,_\n",
    "* _Get the Data,_\n",
    "* _Explore and Visualize the Data to Gain Insights,_ \n",
    "* _Prepare the Data for Machine Learning Algorithms,_\n",
    "* _Select and Train a Model,_\n",
    "* _Fine-Tune Your Model,_\n",
    "* _Launch, Monitor, and Maintain Your System,_\n",
    "* (_Try It Out!._  er afslutning af kapitel, skal ikke resumeres).\n",
    "\n",
    "## På klassen\n",
    "\n",
    "Supergruppe [SG] resume af § 2 End-to-End, ca. 30 til 45 min.\n",
    "\n",
    "* en supergruppe [SG], sammensættes af to grupper [G], on-the-fly på klassen,\n",
    "\n",
    "* hver gruppe [G] forbereder og giver en anden gruppe [G] et mundtligt resume af § 2 til en anden gruppe,\n",
    "\n",
    "* tid: ca. 30 mim. sammenlagt, den ene grupper genfortæller første halvdel af § 2 i ca. 15 min., hvorefter den anden gruppe genfortæller resten i ca. 15 min."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resume: Look at the Big Picture\n",
    "Et ML-projekt starter ikke i Jupyter, men i virkeligheden. Først skal problemet skæres til: hvad prøver vi at løse, og hvordan ser succes ud for dem, der skal bruge løsningen? Vi afgør, om opgaven er regression, klassifikation eller noget tredje, og vælger metrics, der giver mening for forretningen. Samtidig afklarer vi rammerne: hvilke data findes, hvor rene er de, og er der krav til hastighed, forklarbarhed eller fairness? En simpel baseline fungerer som reality check, så vi kan se, om modellen faktisk slår en tommelfingerregel. Til sidst planlægger vi, hvordan data og feedback løbende kommer tilbage i systemet, så modellen kan blive klogere uden at vi starter forfra hver gang.\n",
    "\n",
    "#### Resume: Get the Data\n",
    "Her handler det om at gøre dataindhentningen kedeligt pålidelig. Man finder kilderne, laver et stabilt snapshot og tænker over privatliv og lækager, inden man bliver for kreativ. Splittet i træning/validering/test bør ligge tidligt, helst på en måde der minder om drift (fx tidsbaseret, hvis problemet er tidsfølsomt). Pointen er, at både du og en anden i gruppen kan genskabe præcis samme datasæt i morgen, uden overraskelser.\n",
    "\n",
    "#### Resume: Explore and Visualize the Data to Gain Insights,\n",
    "EDA er der, hvor man får fornemmelsen for materialet. Man kigger på fordelinger, outliers og relationer for at se, om der er noget, der stikker ud, eller om visse features faktisk hænger sammen med målet. Visualiseringer er mest et værktøj til at stille bedre spørgsmål: ligner træningsdata de cases, vi forventer i produktion, og ændrer tingene sig over tid eller mellem segmenter? Hypoteserne fra EDA’en er retningsgivende for, hvad vi vil prøve senere, men de skal altid bekræftes ordentligt.\n",
    "\n",
    "#### Resume: Prepare the Data for Machine Learning Algorithms\n",
    "Forbehandling er den praktiske del, der gør datasættet brugbart og reproducerbart. Manglende værdier håndteres fornuftigt, numeriske features skaleres, og kategoriske kodning vælges, så det matcher både model og drift. Ofte opstår de bedste forbedringer gennem simpel feature engineering: rigtige transformationer, aggregeringer eller tidsvinduer. Alt pakkes i en pipeline, så det samme sker på præcis samme måde i træning, validering, test—og senere i produktion. Gem state (scalers, encodere), så inferens ikke “glemmer” forbehandlingen.\n",
    "\n",
    "#### Resume: Select and Train a Model\n",
    "Man starter hellere simpelt end ambitiøst, fordi det giver hurtig feedback og et klart sammenligningsgrundlag. Tabsfunktion og evalueringsmål skal passe til problemet, ellers jagter man tal, der ikke betyder noget. Krydsvalidering giver mere stabile estimater, og undervejs holder man øje med under-/overfitting og justerer kompleksitet og regulering. Alle eksperimenter logges (hyperparametre, seed, versioner), så man kan forklare, hvorfor model A slog model B—eller hvorfor den ikke gjorde.\n",
    "\n",
    "#### Resume: Fine-Tune Your Model\n",
    "Tuning handler om at forbedre generalisering uden at snyde. Man søger hyperparametre systematisk, læser læringskurver for at se, om problemet er “for lidt data” eller “for kompleks model”, og overvejer ensembling, hvis det giver stabil gevinst. Det hele balanceres mod praktiske krav: modelstørrelse, latenstid og fortolkbarhed. Den endelige vurdering sker én gang på test-sættet, hvorefter model og pipeline fryses, så man ved, hvad der faktisk blev godkendt.\n",
    "\n",
    "#### Resume: Launch, Monitor, and Maintain Your System\n",
    "I produktion er modellen kun én brik i et system. Man pakker den som service eller batch-job, laver ordentlig versionering og automatiserede tests, og sætter overvågning op på både data og effekt: driftsdrift (data drift), latency, fejl og de KPI’er, der betyder noget for brugerne. Når ting ændrer sig, har man en plan for rollback og kontrollerede udrulninger. Retræning sker efter en tydelig strategi (tid eller triggers), og alt registreres i et model-registry, så man kan audit-spore ændringer. Etik og bias er ikke et engangscheck; det er noget, der genbesøges, når data og brugere udvikler sig.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    ":- | :- |\n",
    "2019-01-28| CEF, initial.\n",
    "2020-02-05| CEF, F20 ITMAL update.\n",
    "2021-08-17| CEF, E21 ITMAL update.\n",
    "2021-09-17| CEF, corrected some spell errors.\n",
    "2022-01-28| CEF, update to F22 SWMAL.\n",
    "2022-09-09| CEF, corrected 'MUST for O1' to 'MUST for O2' in text.\n",
    "2023-02-13| CEF, updated to HOML 3rd, removed exclude subsections in 'Get the Data' in this excercise, since the parts with python environments has been removed in HOML.\n",
    "2024-02-14| CEF, removed resume of 'Try-it-out'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
